{"0": "       numFeatures = input.map(_.features.size).first()\n    ", "1": "     val numInvalid = data.filter(x => x.label != 1.0 && x.label != 0.0).count()\n    ", "10": "     ", "11": "   ", "12": "     ).sortByKey(ascending = false)\n     val counts = scoreAndLabels.combineByKey(\n     ).sortByKey(ascending = false)\n", "16": "     val counts = scoreAndLabels.combineByKey(\n", "17": "     val agg = binnedCounts.values.mapPartitions { iter =>\n     val agg = binnedCounts.values.mapPartitions { iter =>\n     ).sortByKey(ascending = false)\n", "2": "           input.map(lp => (lp.label, lp.features))\n    ", "22": "       val (sizes, heads) = parent.mapPartitions { iter =>\n     val first = sc.makeRDD(Seq((0.0, 0.0)), 1)\n     val cumulativeCounts = binnedCounts.mapPartitionsWithIndex(\n     new UnionRDD[(Double, Double)](sc, Seq(first, rocCurve, last))\n     ).sortByKey(ascending = false)\n     confusions.map { case (_, c) =>\n     val confusions = cumulativeCounts.map { case (score, cumCount) =>\n     val last = sc.makeRDD(Seq((1.0, 1.0)), 1)\n", "27": "   extends RDD[Array[T]](parent) {\n     val first = sc.makeRDD(Seq((0.0, 0.0)), 1)\n     val cumulativeCounts = binnedCounts.mapPartitionsWithIndex(\n     new UnionRDD[(Double, Double)](sc, Seq(first, rocCurve, last))\n     ).sortByKey(ascending = false)\n     confusions.map { case (_, c) =>\n     val confusions = cumulativeCounts.map { case (score, cumCount) =>\n     val last = sc.makeRDD(Seq((1.0, 1.0)), 1)\n", "3": "         .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n              input.map(lp => (lp.label, lp.features))\n          .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n       val (gradientSum, lossSum, miniBatchSize) = data.sample(false, miniBatchFraction, 42 + i)\n", "4": "         .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n         .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n", "5": "         .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n           .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n        val (gradientSum, lossSum, miniBatchSize) = data.sample(false, miniBatchFraction, 42 + i)\n           input.map(lp => (lp.label, lp.features))\n ", "6": "         .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n         .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n", "7": "         .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n          val (gradientSum, lossSum, miniBatchSize) = data.sample(false, miniBatchFraction, 42 + i)\n         .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n           input.map(lp => (lp.label, lp.features))\n ", "8": "         .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n         .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n", "9": "    "}