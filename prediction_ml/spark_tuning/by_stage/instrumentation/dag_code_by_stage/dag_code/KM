{"0": "    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n   /**\n     val data = sc.textFile(input)\n     val parsedData = data.map(s => Vectors.dense(s.split(' ').map(_.toDouble))).cache()\n     val data = sc.textFile(input)\n", "1": " @Since(\"1.6.0\")\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n   /**\n     val data = sc.textFile(input)\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n     val parsedData = data.map(s => Vectors.dense(s.split(' ').map(_.toDouble))).cache()\n     val data = sc.textFile(input)\n", "10": " \n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n   /**\n     val data = sc.textFile(input)\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n     val parsedData = data.map(s => Vectors.dense(s.split(' ').map(_.toDouble))).cache()\n     val data = sc.textFile(input)\n", "11": "   def setInitMode(value: String): this.type = set(initMode, value)\n", "12": "     vectorsAndClusterIdx.saveAsTextFile(output)\n     val vectorsAndClusterIdx = parsedData.map { point =>\n     val data = sc.textFile(input)\n     val parsedData = data.map(s => Vectors.dense(s.split(' ').map(_.toDouble))).cache()\n     val data = sc.textFile(input)\n", "13": "     val cost = data.map(p =>\n     val data = sc.textFile(input)\n     val parsedData = data.map(s => Vectors.dense(s.split(' ').map(_.toDouble))).cache()\n     val data = sc.textFile(input)\n", "2": "  *                     points in the training dataset). This is equivalent to sklearn's inertia.\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n   /**\n     val data = sc.textFile(input)\n     validateAndTransformSchema(schema)\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n     val parsedData = data.map(s => Vectors.dense(s.split(' ').map(_.toDouble))).cache()\n  *                     points in the training dataset). This is equivalent to sklearn's inertia.\n     val data = sc.textFile(input)\n", "3": "     k: Int,\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n   /**\n  *                     points in the training dataset). This is equivalent to sklearn's inertia.\n     k: Int,\n     val data = sc.textFile(input)\n     validateAndTransformSchema(schema)\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n     val parsedData = data.map(s => Vectors.dense(s.split(' ').map(_.toDouble))).cache()\n     val data = sc.textFile(input)\n  *                     points in the training dataset). This is equivalent to sklearn's inertia.\n", "4": "  *                     points in the training dataset). This is equivalent to sklearn's inertia.\n  *                     points in the training dataset). This is equivalent to sklearn's inertia.\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n   /**\n  *                     points in the training dataset). This is equivalent to sklearn's inertia.\n     val data = sc.textFile(input)\n     validateAndTransformSchema(schema)\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n     val parsedData = data.map(s => Vectors.dense(s.split(' ').map(_.toDouble))).cache()\n     val data = sc.textFile(input)\n  *                     points in the training dataset). This is equivalent to sklearn's inertia.\n", "5": "     k: Int,\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n   /**\n  *                     points in the training dataset). This is equivalent to sklearn's inertia.\n  *                     points in the training dataset). This is equivalent to sklearn's inertia.\n  *                     points in the training dataset). This is equivalent to sklearn's inertia.\n     k: Int,\n     val data = sc.textFile(input)\n     validateAndTransformSchema(schema)\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n     val parsedData = data.map(s => Vectors.dense(s.split(' ').map(_.toDouble))).cache()\n     val data = sc.textFile(input)\n  *                     points in the training dataset). This is equivalent to sklearn's inertia.\n", "6": "         .countByValue()\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n   /**\n     val data = sc.textFile(input)\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n         .map(distanceMeasureInstance.findClosest(bcCenters.value, _)._1)\n         .countByValue()\n     val parsedData = data.map(s => Vectors.dense(s.split(' ').map(_.toDouble))).cache()\n     val data = sc.textFile(input)\n", "7": "         .countByValue()\n", "8": " \n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n   /**\n     val data = sc.textFile(input)\n    * Spark 1.6 and earlier. A model can be loaded from such older data for backward compatibility.\n     val parsedData = data.map(s => Vectors.dense(s.split(' ').map(_.toDouble))).cache()\n     val data = sc.textFile(input)\n", "9": "   def setInitMode(value: String): this.type = set(initMode, value)\n"}