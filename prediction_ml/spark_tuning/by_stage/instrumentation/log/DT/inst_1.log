org/apache/spark/status/api/v1/OutputMetrics.bytesWritten-api.scala-241-241=10
org/apache/spark/rdd/RDD.doCheckpoint-RDD.scala-1800-1800=6
org/apache/spark/mllib/regression/LabeledPoint.features-LabeledPoint.scala-38-38=1
org/apache/spark/status/api/v1/TaskMetrics.resultSize-api.scala-225-225=6
org/apache/spark/rdd/MapPartitionsRDD.initializeLogIfNecessary-MapPartitionsRDD.scala-77-77=2
org/apache/spark/rdd/RDD.org$apache$spark$rdd$RDD$$partitions_-RDD.scala-242-242=62
org/apache/spark/status/api/v1/ShuffleReadMetrics.localBlocksFetched-api.scala-246-246=6
org/apache/spark/rdd/RDD.org$apache$spark$rdd$RDD$$sc-RDD.scala-89-100=7
org/apache/spark/rdd/HadoopRDD.jobConfCacheKey-HadoopRDD.scala-127-127=2
org/apache/spark/mllib/tree/RandomForest$$anonfun$8.apply-RandomForest.scala-94-94=2
org/apache/spark/rdd/RDD.id-RDD.scala-150-150=55
org/apache/spark/rdd/RDD.scope-RDD.scala-1743-1743=11
org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$5.apply-HadoopRDD.scala-177-177=1
org/apache/spark/status/api/v1/InputMetrics.recordsRead-api.scala-238-238=10
org/apache/spark/rdd/RDD$$anonfun$take$1$$anonfun$31.apply-RDD.scala-1409-1409=2
org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$5.apply-JsonProtocol.scala-440-440=46
org/apache/spark/status/api/v1/ShuffleWriteMetrics.writeTime-api.scala-255-255=6
org/apache/spark/status/api/v1/TaskMetrics.peakExecutionMemory-api.scala-230-230=6
org/apache/spark/status/api/v1/TaskMetrics.shuffleWriteMetrics-api.scala-234-234=26
org/apache/spark/rdd/RDD$$anonfun$take$1.org$apache$spark$rdd$RDD$$anonfun$$$outer-RDD.scala-1382-1382=1
org/apache/spark/status/api/v1/StageData.attemptId-api.scala-166-166=4
org/apache/spark/rdd/RDD$$anonfun$take$1$$anonfun$apply$48.apply-RDD.scala-1411-1411=1
org/apache/spark/status/api/v1/StageData.stageId-api.scala-165-165=4
org/apache/spark/status/api/v1/ShuffleReadMetrics.remoteBytesReadToDisk-api.scala-249-249=6
org/apache/spark/rdd/RDD.getNarrowAncestors-RDD.scala-320-335=2
org/apache/spark/rdd/RDD.logDebug-RDD.scala-77-77=1
org/apache/spark/rdd/HadoopRDD$$anon$1.org$apache$spark$rdd$HadoopRDD$$anon$$updateBytesRead-HadoopRDD.scala-254-254=2
org/apache/spark/rdd/RDD.take-RDD.scala-1382-1382=1
org/apache/spark/rdd/HadoopRDD$$anonfun$convertSplitLocationInfo$1$$anonfun$apply$5.apply-HadoopRDD.scala-434-434=2
org/apache/spark/rdd/RDD.isCheckpointedAndMaterialized-RDD.scala-1677-1677=6
org/apache/spark/status/api/v1/TaskMetrics.memoryBytesSpilled-api.scala-228-228=10
org/apache/spark/rdd/HadoopRDD$$anon$1.close-HadoopRDD.scala-314-314=1
org/apache/spark/rdd/HadoopRDD$$anon$1$$anonfun$org$apache$spark$rdd$HadoopRDD$$anon$$updateBytesRead$1.apply-HadoopRDD.scala-254-254=2
org/apache/spark/rdd/RDD.withScope-RDD.scala-385-385=1
org/apache/spark/rdd/RDD.org$apache$spark$rdd$RDD$$doCheckpointCalled-RDD.scala-1792-1792=6
org/apache/spark/rdd/HadoopPartition.inputSplit-HadoopRDD.scala-51-51=6
org/apache/spark/status/api/v1/ShuffleReadMetrics.recordsRead-api.scala-251-251=10
org/apache/spark/rdd/RDD$$anonfun$org$apache$spark$rdd$RDD$$visit$1$1.apply-RDD.scala-326-326=9
org/apache/spark/status/api/v1/OutputMetrics.recordsWritten-api.scala-242-242=10
org/apache/spark/rdd/HadoopRDD$$anonfun$convertSplitLocationInfo$1.apply-HadoopRDD.scala-434-434=4
org/apache/spark/rdd/RDD.creationSite-RDD.scala-1734-1734=11
org/apache/spark/mllib/linalg/Vector$class.$init$-Vectors.scala-47-47=1
org/apache/spark/rdd/RDD$$anonfun$6.apply-RDD.scala-325-325=18
org/apache/spark/rdd/RDD.log-RDD.scala-77-77=3
org/apache/spark/rdd/RDD$$anonfun$preferredLocations$2.apply-RDD.scala-297-297=10
org/apache/spark/rdd/RDD.org$apache$spark$rdd$RDD$$dependencies_-RDD.scala-241-241=102
org/apache/spark/status/api/v1/TaskMetrics.executorCpuTime-api.scala-224-224=10
org/apache/spark/rdd/RDDOperationScope.toJson-RDDOperationScope.scala-52-52=28
org/apache/spark/rdd/RDD.org$apache$spark$rdd$RDD$$visit$1-RDD.scala-323-326=11
org/apache/spark/rdd/RDD.isBarrier-RDD.scala-1931-1931=4
org/apache/spark/rdd/HadoopPartition.index-HadoopRDD.scala-48-48=7
org/apache/spark/api/java/JavaPairRDD$$anonfun$toScalaFunction$1.apply-JavaPairRDD.scala-1040-1040=1
org/apache/spark/mllib/linalg/Vectors$.parseNumeric-Vectors.scala-395-401=1
org/apache/spark/status/api/v1/InputMetrics.bytesRead-api.scala-237-237=10
org/apache/spark/mllib/regression/LabeledPoint$.parse-LabeledPoint.scala-61-61=1
org/apache/spark/rdd/RDD.getPreferredLocations-RDD.scala-137-137=8
org/apache/spark/status/api/v1/ExecutorSummary.hostPort-api.scala-78-78=3
org/apache/spark/mllib/regression/LabeledPoint.asML-LabeledPoint.scala-44-44=1
org/apache/spark/rdd/RDD$$anonfun$doCheckpoint$1.apply-RDD.scala-1801-1801=6
org/apache/spark/rdd/MapPartitionsRDD.computeOrReadCheckpoint-MapPartitionsRDD.scala-343-343=6
org/apache/spark/rdd/HadoopRDD$$anon$1$$anonfun$3.apply-HadoopRDD.scala-284-285=1
org/apache/spark/rdd/RDD.iterator-RDD.scala-307-307=6
org/apache/spark/status/api/v1/ShuffleWriteMetrics.bytesWritten-api.scala-254-254=10
org/apache/spark/rdd/MapPartitionsRDD.org$apache$spark$internal$Logging$$log_-MapPartitionsRDD.scala-77-77=6
org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$7.apply-JsonProtocol.scala-444-444=46
org/apache/spark/rdd/RDDOperationScope$.$lessinit$greater$default$2-RDDOperationScope.scala-48-48=6
org/apache/spark/rdd/RDDOperationScope$$anonfun$getAllScopes$2.apply-RDDOperationScope.scala-61-61=6
org/apache/spark/rdd/RDD.firstParent-RDD.scala-1763-1763=5
org/apache/spark/rdd/RDDOperationScope$.withScope-RDDOperationScope.scala-134-155=7
org/apache/spark/rdd/RDDOperationScope.getAllScopes-RDDOperationScope.scala-61-61=6
org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$2.apply-JsonProtocol.scala-437-437=44
org/apache/spark/status/api/v1/ShuffleReadMetrics.remoteBytesRead-api.scala-248-248=10
org/apache/spark/rdd/InputFileBlockHolder$.unset-InputFileBlockHolder.scala-86-86=2
org/apache/spark/rdd/HadoopRDD$.addLocalConfiguration-HadoopRDD.scala-401-408=1
org/apache/spark/rdd/RDD$$anonfun$take$1.apply-RDD.scala-1383-1382=1
org/apache/spark/rdd/HadoopRDD$$anonfun$getJobConf$5$$anonfun$apply$3.apply-HadoopRDD.scala-180-180=2
org/apache/spark/status/api/v1/TaskMetrics.executorRunTime-api.scala-223-223=10
org/apache/spark/status/api/v1/TaskMetrics.inputMetrics-api.scala-231-231=20
org/apache/spark/rdd/RDDOperationScope.name-RDDOperationScope.scala-47-47=34
org/apache/spark/rdd/RDD$$anonfun$5.apply-RDD.scala-324-324=18
org/apache/spark/rdd/MapPartitionsRDD.org$apache$spark$internal$Logging$$log__$eq-MapPartitionsRDD.scala-77-77=1
org/apache/spark/rdd/HadoopRDD$.org$apache$spark$internal$Logging$$log__$eq-HadoopRDD.scala-379-379=1
org/apache/spark/rdd/MapPartitionsRDD.logInfo-MapPartitionsRDD.scala-77-77=1
org/apache/spark/rdd/HadoopRDD$$anon$1$$anonfun$org$apache$spark$rdd$HadoopRDD$$anon$$updateBytesRead$1.apply-HadoopRDD.scala-255-255=2
org/apache/spark/rdd/RDD.name-RDD.scala-153-153=11
org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$6.apply-JsonProtocol.scala-443-443=46
org/apache/spark/rdd/HadoopRDD$$anon$1.getNext-HadoopRDD.scala-224-224=1
org/apache/spark/rdd/RDD$$anonfun$dependencies$2.apply-RDD.scala-252-252=51
org/apache/spark/rdd/RDD.computeOrReadCheckpoint-RDD.scala-343-343=6
org/apache/spark/rdd/HadoopRDD$$anon$1.org$apache$spark$rdd$HadoopRDD$$anon$$existingBytesRead-HadoopRDD.scala-231-231=2
org/apache/spark/rdd/RDD.org$apache$spark$internal$Logging$$log_-RDD.scala-77-77=6
org/apache/spark/mllib/regression/LabeledPoint.label-LabeledPoint.scala-37-37=1
org/apache/spark/rdd/HadoopRDD$$anon$1$$anonfun$2.apply-HadoopRDD.scala-227-227=1
org/apache/spark/rdd/HadoopRDD$$anon$1.org$apache$spark$rdd$HadoopRDD$$anon$$inputMetrics-HadoopRDD.scala-230-230=5
org/apache/spark/status/api/v1/TaskMetrics.outputMetrics-api.scala-232-232=20
org/apache/spark/rdd/MapPartitionsRDD.logDebug-MapPartitionsRDD.scala-77-77=1
org/apache/spark/rdd/HadoopRDD$.CONFIGURATION_INSTANTIATION_LOCK-HadoopRDD.scala-384-384=1
org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$8.apply-JsonProtocol.scala-445-445=46
org/apache/spark/mllib/regression/LabeledPoint.parse-LabeledPoint.scala--1--1=1
org/apache/spark/status/api/v1/TaskMetrics.executorDeserializeCpuTime-api.scala-222-222=6
org/apache/spark/rdd/RDD.preferredLocations-RDD.scala-296-296=10
org/apache/spark/rdd/MapPartitionsRDD.logName-MapPartitionsRDD.scala-77-77=1
org/apache/spark/rdd/RDD.dependencies-RDD.scala-252-252=51
org/apache/spark/mllib/util/NumericParser$.parse-NumericParser.scala-37-49=1
org/apache/spark/rdd/RDD.logName-RDD.scala-77-77=1
org/apache/spark/status/api/v1/ShuffleReadMetrics.fetchWaitTime-api.scala-247-247=6
org/apache/spark/rdd/MapPartitionsRDD.isBarrier_-MapPartitionsRDD.scala-60-60=4
org/apache/spark/rdd/RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply-RDD.scala-823-823=2
org/apache/spark/rdd/HadoopRDD.getJobConf-HadoopRDD.scala-144-153=1
org/apache/spark/rdd/RDD$$anonfun$map$1$$anonfun$apply$5.apply-RDD.scala-394-394=8
org/apache/spark/mllib/linalg/DenseVector.values-Vectors.scala-617-617=1
org/apache/spark/status/api/v1/TaskMetrics.shuffleReadMetrics-api.scala-233-233=54
org/apache/spark/rdd/HadoopRDD$$anonfun$convertSplitLocationInfo$1$$anonfun$apply$5.apply-HadoopRDD.scala-435-434=2
org/apache/spark/status/api/v1/ShuffleReadMetrics.remoteBlocksFetched-api.scala-245-245=6
org/apache/spark/status/api/v1/ShuffleWriteMetrics.recordsWritten-api.scala-256-256=10
org/apache/spark/status/api/v1/TaskMetrics.diskBytesSpilled-api.scala-229-229=10
org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$1.apply-JsonProtocol.scala-437-437=44
org/apache/spark/status/api/v1/TaskMetrics.resultSerializationTime-api.scala-227-227=6
org/apache/spark/rdd/RDD$$anonfun$partitions$2.apply-RDD.scala-269-269=31
org/apache/spark/rdd/RDD.getStorageLevel-RDD.scala-223-223=16
org/apache/spark/rdd/MapPartitionsRDD.isCheckpointedAndMaterialized-MapPartitionsRDD.scala-1677-1677=6
org/apache/spark/rdd/RDDOperationScope.id-RDDOperationScope.scala-49-49=34
org/apache/spark/rdd/RDD$$anonfun$doCheckpoint$1$$anonfun$apply$mcV$sp$2.apply-RDD.scala-1813-1813=10
org/apache/spark/rdd/RDD$$anonfun$4.apply-RDD.scala-323-323=18
org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$4$$anonfun$apply$19.apply-JsonProtocol.scala-439-439=46
org/apache/spark/rdd/InputFileBlockHolder$$anon$1.initialValue-InputFileBlockHolder.scala-53-53=1
org/apache/spark/rdd/RDD.sparkContext-RDD.scala-147-147=1
org/apache/spark/rdd/RDDOperationScope$.org$apache$spark$rdd$RDDOperationScope$$jsonMapper-RDDOperationScope.scala-82-82=34
org/apache/spark/rdd/InputFileBlockHolder$.initialize-InputFileBlockHolder.scala-92-92=1
org/apache/spark/rdd/RDD$$anonfun$retag$1.apply-RDD.scala-1788-1788=2
org/apache/spark/rdd/HadoopRDD$.org$apache$spark$rdd$HadoopRDD$$putCachedMetadata-HadoopRDD.scala-396-396=1
org/apache/spark/rdd/RDDOperationScope$.withScope-RDDOperationScope.scala-102-112=1
org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$9.apply-JsonProtocol.scala-446-446=46
org/apache/spark/rdd/HadoopRDD.getPreferredLocations-HadoopRDD.scala-354-360=2
org/apache/spark/rdd/RDDOperationScope$.nextScopeId-RDDOperationScope.scala-90-90=6
org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$3.apply-JsonProtocol.scala-439-439=44
org/apache/spark/rdd/RDD.checkpointData-RDD.scala-1751-1751=104
org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$4.apply-JsonProtocol.scala-439-439=46
org/apache/spark/rdd/HadoopRDD$.getCachedMetadata-HadoopRDD.scala-393-393=1
org/apache/spark/status/api/v1/ShuffleReadMetrics.localBytesRead-api.scala-250-250=10
org/apache/spark/rdd/HadoopRDD.getInputFormat-HadoopRDD.scala-190-196=1
org/apache/spark/rdd/HadoopRDD$$anon$1$$anonfun$3.apply-HadoopRDD.scala-281-281=1
org/apache/spark/rdd/MapPartitionsRDD.compute-MapPartitionsRDD.scala-52-52=5
org/apache/spark/rdd/RDDOperationScope$$anonfun$5.apply-RDDOperationScope.scala-137-137=12
org/apache/spark/rdd/RDD$$anonfun$doCheckpoint$1.apply$mcV$sp-RDD.scala-1801-1801=6
org/apache/spark/rdd/MapPartitionsRDD.org$apache$spark$rdd$RDD$$dependencies_-MapPartitionsRDD.scala-241-241=10
org/apache/spark/status/api/v1/TaskMetrics.executorDeserializeTime-api.scala-221-221=7
org/apache/spark/rdd/RDD$$anonfun$getNarrowAncestors$1.apply-RDD.scala-335-335=18
org/apache/spark/rdd/RDD.org$apache$spark$internal$Logging$$log__$eq-RDD.scala-77-77=1
org/apache/spark/rdd/HadoopRDD.org$apache$spark$rdd$HadoopRDD$$createTime-HadoopRDD.scala-132-132=1
org/apache/spark/rdd/MapPartitionsRDD.dependencies-MapPartitionsRDD.scala-252-252=5
org/apache/spark/rdd/MapPartitionsRDD.log-MapPartitionsRDD.scala-77-77=3
org/apache/spark/rdd/RDD.logInfo-RDD.scala-77-77=1
org/apache/spark/rdd/RDD.org$apache$spark$rdd$RDD$$doCheckpointCalled_$eq-RDD.scala-1792-1792=6
org/apache/spark/rdd/RDDOperationScope$.fromJson-RDDOperationScope.scala-86-86=6
org/apache/spark/rdd/MapPartitionsRDD.firstParent-MapPartitionsRDD.scala-1763-1763=5
org/apache/spark/rdd/HadoopRDD$.convertSplitLocationInfo-HadoopRDD.scala-434-434=2
org/apache/spark/rdd/HadoopRDD$$anon$1.org$apache$spark$rdd$HadoopRDD$$anon$$split-HadoopRDD.scala-226-226=4
org/apache/spark/rdd/InputFileBlockHolder$.set-InputFileBlockHolder.scala-77-80=1
org/apache/spark/rdd/HadoopRDD.compute-HadoopRDD.scala-95-95=1
org/apache/spark/rdd/RDDOperationScope.parent-RDDOperationScope.scala-48-48=34
org/apache/spark/rdd/RDD.partitions-RDD.scala-269-269=31
org/apache/spark/rdd/RDD.initializeLogIfNecessary-RDD.scala-77-77=2
org/apache/spark/status/api/v1/JobData.jobId-api.scala-110-110=2
org/apache/spark/status/api/v1/ExecutorSummary.id-api.scala-77-77=3
org/apache/spark/rdd/MapPartitionsRDD.checkpointData-MapPartitionsRDD.scala-1751-1751=11
org/apache/spark/mllib/linalg/Vectors$.dense-Vectors.scala-308-308=1
org/apache/spark/status/api/v1/TaskMetrics.jvmGcTime-api.scala-226-226=6
org/apache/spark/mllib/linalg/DenseVector.asML-Vectors.scala-616-616=1
org/apache/spark/rdd/MapPartitionsRDD.iterator-MapPartitionsRDD.scala-307-307=6
org/apache/spark/rdd/RDD$$anonfun$org$apache$spark$rdd$RDD$$visit$1$1.apply-RDD.scala-327-328=9
org/apache/spark/rdd/RDDOperationScope$.$lessinit$greater$default$3-RDDOperationScope.scala-49-49=6
