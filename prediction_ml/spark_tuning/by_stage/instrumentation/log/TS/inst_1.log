org/apache/spark/status/api/v1/OutputMetrics.bytesWritten-api.scala-241-241=2
org/apache/spark/rdd/InputFileBlockHolder$.unset-InputFileBlockHolder.scala-86-86=4
org/apache/spark/rdd/NewHadoopRDD.iterator-NewHadoopRDD.scala-307-307=2
org/apache/spark/status/api/v1/TaskMetrics.executorRunTime-api.scala-223-223=2
org/apache/spark/status/api/v1/TaskMetrics.inputMetrics-api.scala-231-231=4
org/apache/spark/rdd/NewHadoopRDD$$anon$1$$anonfun$3.apply-NewHadoopRDD.scala-220-221=2
org/apache/spark/rdd/RDD.name-RDD.scala-153-153=1
org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$6.apply-JsonProtocol.scala-443-443=2
org/apache/spark/rdd/NewHadoopRDD$$anon$1.org$apache$spark$rdd$NewHadoopRDD$$anon$$updateBytesRead-NewHadoopRDD.scala-181-181=4
org/apache/spark/rdd/ShuffledRDDPartition.index-ShuffledRDD.scala-27-27=2
org/apache/spark/rdd/NewHadoopRDD.initializeLogIfNecessary-NewHadoopRDD.scala-77-77=4
org/apache/spark/rdd/RDD$$anonfun$dependencies$2.apply-RDD.scala-252-252=11
org/apache/spark/rdd/RDD.computeOrReadCheckpoint-RDD.scala-343-343=2
org/apache/spark/rdd/RDD.org$apache$spark$rdd$RDD$$partitions_-RDD.scala-242-242=28
org/apache/spark/rdd/RDD.org$apache$spark$internal$Logging$$log_-RDD.scala-77-77=8
org/apache/spark/status/api/v1/TaskMetrics.outputMetrics-api.scala-232-232=4
org/apache/spark/rdd/NewHadoopRDD$$anon$1.next-NewHadoopRDD.scala-151-151=10
org/apache/spark/rdd/RDD.id-RDD.scala-150-150=24
org/apache/spark/rdd/RDD.scope-RDD.scala-1743-1743=1
org/apache/spark/status/api/v1/InputMetrics.recordsRead-api.scala-238-238=2
org/apache/spark/util/JsonProtocol$$anonfun$rddInfoToJson$5.apply-JsonProtocol.scala-440-440=2
org/apache/spark/rdd/NewHadoopRDD$$anon$1.org$apache$spark$rdd$NewHadoopRDD$$anon$$close-NewHadoopRDD.scala-269-269=4
org/apache/spark/rdd/NewHadoopRDD.checkpointData-NewHadoopRDD.scala-1751-1751=2
org/apache/spark/status/api/v1/TaskMetrics.shuffleWriteMetrics-api.scala-234-234=4
org/apache/spark/rdd/RDD.preferredLocations-RDD.scala-296-296=6
org/apache/spark/rdd/RDD.dependencies-RDD.scala-252-252=11
org/apache/spark/status/api/v1/StageData.attemptId-api.scala-166-166=2
org/apache/spark/rdd/NewHadoopRDD.getConf-NewHadoopRDD.scala-98-107=2
org/apache/spark/rdd/NewHadoopRDD$$anon$1$$anonfun$3.apply-NewHadoopRDD.scala-217-217=2
org/apache/spark/rdd/RDD.logName-RDD.scala-77-77=2
org/apache/spark/rdd/NewHadoopRDD$$anon$1$$anonfun$2.apply-NewHadoopRDD.scala-153-153=2
org/apache/spark/status/api/v1/StageData.stageId-api.scala-165-165=2
org/apache/spark/rdd/RDD.getNarrowAncestors-RDD.scala-320-335=1
org/apache/spark/rdd/NewHadoopRDD$$anon$1.org$apache$spark$rdd$NewHadoopRDD$$anon$$split-NewHadoopRDD.scala-152-152=12
org/apache/spark/rdd/ShuffledRDD.getPreferredLocations-ShuffledRDD.scala-97-99=2
org/apache/spark/rdd/RDD.isBarrier_-RDD.scala-1935-1935=2
org/apache/spark/status/api/v1/TaskMetrics.shuffleReadMetrics-api.scala-233-233=6
org/apache/spark/status/api/v1/TaskMetrics.memoryBytesSpilled-api.scala-228-228=2
org/apache/spark/rdd/RDD.isCheckpointedAndMaterialized-RDD.scala-1677-1677=2
org/apache/spark/status/api/v1/ShuffleWriteMetrics.recordsWritten-api.scala-256-256=2
org/apache/spark/status/api/v1/TaskMetrics.diskBytesSpilled-api.scala-229-229=2
org/apache/spark/rdd/NewHadoopRDD$$anon$1.org$apache$spark$rdd$NewHadoopRDD$$anon$$inputMetrics-NewHadoopRDD.scala-156-156=26
org/apache/spark/rdd/NewHadoopRDD.org$apache$spark$rdd$NewHadoopRDD$$jobTrackerId-NewHadoopRDD.scala-82-82=2
org/apache/spark/rdd/NewHadoopRDD$$anon$1.hasNext-NewHadoopRDD.scala-228-229=24
org/apache/spark/status/api/v1/ShuffleReadMetrics.recordsRead-api.scala-251-251=2
org/apache/spark/status/api/v1/OutputMetrics.recordsWritten-api.scala-242-242=2
org/apache/spark/rdd/NewHadoopRDD.logInfo-NewHadoopRDD.scala-77-77=2
org/apache/spark/rdd/NewHadoopRDD$$anon$1.org$apache$spark$rdd$NewHadoopRDD$$anon$$existingBytesRead-NewHadoopRDD.scala-157-157=4
org/apache/spark/rdd/RDD.creationSite-RDD.scala-1734-1734=1
org/apache/spark/rdd/NewHadoopRDD$$anon$1$$anonfun$org$apache$spark$rdd$NewHadoopRDD$$anon$$updateBytesRead$1.apply-NewHadoopRDD.scala-181-181=4
org/apache/spark/rdd/RDD$$anonfun$partitions$2.apply-RDD.scala-269-269=14
org/apache/spark/rdd/RDD.getStorageLevel-RDD.scala-223-223=4
org/apache/spark/rdd/RDD.log-RDD.scala-77-77=4
org/apache/spark/rdd/RDD$$anonfun$preferredLocations$2.apply-RDD.scala-297-297=6
org/apache/spark/rdd/RDD.org$apache$spark$rdd$RDD$$dependencies_-RDD.scala-241-241=22
org/apache/spark/rdd/InputFileBlockHolder$$anon$1.initialValue-InputFileBlockHolder.scala-53-53=2
org/apache/spark/rdd/RDD.sparkContext-RDD.scala-147-147=1
org/apache/spark/status/api/v1/TaskMetrics.executorCpuTime-api.scala-224-224=2
org/apache/spark/rdd/InputFileBlockHolder$.initialize-InputFileBlockHolder.scala-92-92=2
org/apache/spark/rdd/NewHadoopPartition.serializableHadoopSplit-NewHadoopRDD.scala-49-49=10
org/apache/spark/rdd/NewHadoopRDD.logName-NewHadoopRDD.scala-77-77=2
org/apache/spark/rdd/RDD.checkpointData-RDD.scala-1751-1751=33
org/apache/spark/status/api/v1/ShuffleReadMetrics.localBytesRead-api.scala-250-250=2
org/apache/spark/rdd/RDD.org$apache$spark$rdd$RDD$$visit$1-RDD.scala-323-326=1
org/apache/spark/rdd/RDD.isBarrier-RDD.scala-1931-1931=2
org/apache/spark/status/api/v1/InputMetrics.bytesRead-api.scala-237-237=2
org/apache/spark/rdd/RDD.getPreferredLocations-RDD.scala-137-137=4
org/apache/spark/rdd/NewHadoopRDD.computeOrReadCheckpoint-NewHadoopRDD.scala-343-343=2
org/apache/spark/rdd/RDD.org$apache$spark$internal$Logging$$log__$eq-RDD.scala-77-77=2
org/apache/spark/rdd/RDD.logInfo-RDD.scala-77-77=2
org/apache/spark/rdd/RDD.iterator-RDD.scala-307-307=2
org/apache/spark/rdd/NewHadoopRDD.isCheckpointedAndMaterialized-NewHadoopRDD.scala-1677-1677=2
org/apache/spark/status/api/v1/ShuffleWriteMetrics.bytesWritten-api.scala-254-254=2
org/apache/spark/rdd/RDDOperationScope.parent-RDDOperationScope.scala-48-48=1
org/apache/spark/rdd/InputFileBlockHolder$.set-InputFileBlockHolder.scala-77-80=2
org/apache/spark/rdd/RDD.partitions-RDD.scala-269-269=14
org/apache/spark/rdd/RDD.initializeLogIfNecessary-RDD.scala-77-77=4
org/apache/spark/rdd/NewHadoopRDD.org$apache$spark$internal$Logging$$log_-NewHadoopRDD.scala-77-77=8
org/apache/spark/rdd/NewHadoopRDD.compute-NewHadoopRDD.scala-70-70=2
org/apache/spark/rdd/NewHadoopRDD$$anon$1$$anonfun$org$apache$spark$rdd$NewHadoopRDD$$anon$$updateBytesRead$1.apply-NewHadoopRDD.scala-182-182=4
org/apache/spark/rdd/NewHadoopRDD.log-NewHadoopRDD.scala-77-77=4
org/apache/spark/rdd/NewHadoopRDD.id-NewHadoopRDD.scala-150-150=2
org/apache/spark/rdd/NewHadoopRDD.org$apache$spark$internal$Logging$$log__$eq-NewHadoopRDD.scala-77-77=2
org/apache/spark/status/api/v1/ShuffleReadMetrics.remoteBytesRead-api.scala-248-248=2
org/apache/spark/rdd/NewHadoopPartition.index-NewHadoopRDD.scala-45-45=4
